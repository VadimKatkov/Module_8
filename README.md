# Module_8

Олег, день добрый.

Отправляю далеко не самый лучший вариант. Потратил более трех недель на игру с разными вариациями настройки модели. Наилучшего результата добился в самом начале. На Kaggle мой submission составляет 95,94%. Этот результат получил при fine-tuning где применил глобально 4 шага: обучение только головы и потом 3 шага с разморозкой слоев. В конце применил ТТА.

Естественно, решил улучшить результат и начал играться с learning rate, настройками аугментации,  количеством эпох (тут столкнулся с ограничением времени на Colab. Потом читал ваше замечание, что есть платные ресурсы, но было уже поздно), размером картинок.  И попал в заколдованный круг: что-то поменял в базовых настройках в начале так, что максимальный результат до 70% я получал на обучении головы, а потом разморозка слоев не давала мне увеличения accuracy. На это я потратил 2 недели, но так и не нашел своей проблемы. 
Не смотрите на результаты вывода отдельных шагов, так как я уже игрался по разному – старался выполнить все 4 шага, пропускал один шаг, выполнял только обучение головы и последний шаг с полной разморозкой. Смотрите в целом на подход. Буду очень благодарен, если объясните причину, почему я застрял с улучшением accuracy после обучения головы. 

В целом мои выводы:

Базовая модель – Xception
Learning Rate – использовал простой подход: начал с LR = 0,001 на голове и потом уменьшал в 10 раз на каждом шаге разморозки слоев
EPOCHS – больше 10 не применял так как не вкладывался по времени. Хотя как минимум на голове по графику видно, что accuracy показывает постепенный рост. На дополнительных 10 эпохах, думаю можно было бы выиграть еще 2-3 %.
Аугментации – подставлял в начале больше вариаций, но потом увидел, что это затягивает время обучения но не добавляет точности. 
Размер входящей картинки – у меня получилось, что лучше в начале подавать размер картинки меньше и потом наращивать размер по мере разморозки слоев.

Из информации перечитывал только ваши анонимированые отзывы по предыдущим работам.
Хотел еще поиграться и проанализировать ошибки по классам (подготовил экспорты) – но потерял время и уже просто не было сил бороться с тем тупиком, в который попал.


